{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "- **데이터 불러오기 기능** : data_load()\n",
        "- **파라미터와 편향 생성 기능** : initialization_parameter()\n",
        "- **데이터 뒤섞기 기능** : data_shuffle()\n",
        "- **학습 데이터 분리 기능** : train_data_split()\n",
        "- **테스트 데이터 분리 기능** : test_data_split()\n",
        "- **미니배치를 고려한 학습 데이터 기반의 신경망 연산 및 이진 판단 예측 기능** : model_train()\n",
        "- **손실(교차 엔트로피)값 연산 기능** : cross_entropy_loss()\n",
        "- **정확도 연산 기능** : calculate_accuracy()"
      ],
      "metadata": {
        "id": "pGBePByHpQHX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DR6gBgeboSQh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_load(path):\n",
        "  \"\"\"\n",
        "    데이터 불러오는 함수\n",
        "\n",
        "        Args:\n",
        "            path (str) : colab 업로드 된 파일 경로\n",
        "            \n",
        "        Retruns:\n",
        "            data (DataFrame) : binary_dataset.csv\n",
        "  \"\"\"\n",
        "  data = pd.read_csv(path)\n",
        "  return data"
      ],
      "metadata": {
        "id": "oHVBmZciqKeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialization_parameter(inputs):\n",
        "  \"\"\"\n",
        "    가중치 및 편향 생성 함수\n",
        "\n",
        "        Args:\n",
        "            inputs (int) : X_train의 열 갯수 -> 독립변수 x1~x8 8개\n",
        "            \n",
        "        Retruns:\n",
        "            w1 (array) : numpy를 통해 생성된 [0,1]의 범위의 난수를 갖는 8x1 배열\n",
        "            b1 (array) : 0으로 채워진 1차원 배열\n",
        "  \"\"\"\n",
        "  np.random.seed(40)\n",
        "\n",
        "  w1 = np.random.randn(inputs,1)\n",
        "  b1 = np.zeros(1,)\n",
        "\n",
        "  return w1, b1"
      ],
      "metadata": {
        "id": "pTU1xjlDtrg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_shuffle(data):\n",
        "  \"\"\"\n",
        "    DataFrame 행을 무작위로 섞는 함수\n",
        "\n",
        "        Args:\n",
        "            data (DataFrame) : 기존 불러왔던 binary_dataset.csv\n",
        "            \n",
        "        Retruns:\n",
        "            shuffled_data (DataFrame) : binary_dataset.csv의 행의 순서를 무작위로 섞은 후의 데이터 프레임\n",
        "  \"\"\"\n",
        "  shuffled_data = data.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "  return shuffled_data"
      ],
      "metadata": {
        "id": "k2rxU6wsQ9I2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_data_split(data, size=0.8):\n",
        "  \"\"\"\n",
        "    학습 데이터 분리 함수\n",
        "\n",
        "        Args:\n",
        "            data (DataFrame) : data_shuffle에서 반환 된 데이터 프레임\n",
        "            size (int) : 학습 데이터 분리 비중 설정\n",
        "\n",
        "        Retruns:\n",
        "            X_train (DataFrame) : 독립 변수 y를 제외한 index 0~15에 해당하는 16x8 데이터 프레임\n",
        "            y_train (Series) : index 0~15에 해당하는 종속 변수 y 값 16개\n",
        "            \n",
        "        Note:\n",
        "            data.shape[0] : 기존 데이터 프레임의 행의 갯수 20개\n",
        "            data_train : data[:16] 기존 데이터 index 0~15에 해당하는 값 슬라이싱\n",
        "  \"\"\"\n",
        "  num = int(data.shape[0]*size)\n",
        "  data_train = data[:num]\n",
        "  X_train = data_train.drop(['y'], axis=1)\n",
        "  y_train = data_train['y']\n",
        "\n",
        "  return X_train, y_train"
      ],
      "metadata": {
        "id": "CeibiJd9T3gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_data_split(data, size = 0.2):\n",
        "  \"\"\"\n",
        "    테스트 데이터 분리 함수\n",
        "\n",
        "        Args:\n",
        "            data (DataFrame) : data_shuffle에서 반환 된 데이터 프레임\n",
        "            size (int) : 테스트 데이터 분리 비중 설정\n",
        "\n",
        "        Retruns:\n",
        "            X_test (DataFrame) : 독립 변수 y를 제외한 index 0~3에 해당하는 4x8 데이터 프레임\n",
        "            y_test (Series) : index 0~3에 해당하는 종속 변수 y 값 4개\n",
        "            \n",
        "        Note:\n",
        "            data.shape[0] : 기존 데이터 프레임의 행의 갯수 20개\n",
        "            data_train : data[-4:] 기존 데이터 index 16~19에 해당하는 값 슬라이싱\n",
        "  \"\"\"\n",
        "  num = int(data.shape[0]*size)\n",
        "  data_test = data[-num:]\n",
        "  X_test = data_test.drop(['y'], axis=1).reset_index(drop=True)\n",
        "  y_test = data_test['y'].reset_index(drop=True)\n",
        "\n",
        "  return X_test, y_test"
      ],
      "metadata": {
        "id": "2LW5rjcoXxGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_train(X, y, w1, b1, batch_size):\n",
        "  \"\"\"\n",
        "    미니배치를 고려한 학습 데이터 기반의 신경망 연산 및 이진 판단 예측 기능 함수\n",
        "\n",
        "        Args:\n",
        "            X (DataFrame) : 순전파 진행 시 사용 될 독립 변수 데이터 프레임\n",
        "            y (int) : 순전파 진행 시 사용 될 종속 변수 데이터 프레임\n",
        "            w1 (array) : initialization_parameter 함수를 통해 생성된 가중치\n",
        "            b1 (array) : initialization_parameter 함수를 통해 생성된 편향\n",
        "            batch_size (int) : 사용자 지정 batch_size\n",
        "\n",
        "        Retruns:\n",
        "            np.mean(accuracy) (float) : calculate_accuracy 함수를 통해 각 minibatch 마다 계산된 accuracy를 평균 낸 값\n",
        "            np.mean(cross_entropy) (float) : cross_entropy_loss 함수를 통해 각 minibatch 마다 계산된 loss를 평균 낸 값\n",
        "            \n",
        "        Note:\n",
        "            a1 : batch_size에 따른 학습 데이터 분리 후 가중치와 내적, 편향 추가\n",
        "            output : sigmoid 활성화 함수 적용 후 2차원 배열 -> 1차원 배열로 변환 (확률값)\n",
        "            sigmoid_output : output 중 0.5 이상 값은 1로 이하는 0으로 변환 한 배열\n",
        "  \"\"\"\n",
        "  accuracy = []\n",
        "  cross_entropy = []\n",
        "\n",
        "  for i in range(0, len(X), batch_size):\n",
        "    minibatch = X[i:i+batch_size]  \n",
        "    a1 = np.dot(minibatch, w1) + b1\n",
        "    output = np.concatenate(sigmoid(a1).tolist())\n",
        "    sigmoid_output = list(map(lambda x : 1 if x>=0.5 else 0, output))\n",
        "  \n",
        "    accuracy.append(calculate_accuracy(sigmoid_output, y[i:i+batch_size]))\n",
        "    cross_entropy.append(cross_entropy_loss(output, y[i:i+batch_size]))\n",
        "\n",
        "  return np.mean(accuracy), np.mean(cross_entropy)"
      ],
      "metadata": {
        "id": "WTarVKjzMCjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(s):\n",
        "  \"\"\"\n",
        "    sigmoid 활성화 함수를 구현한 함수\n",
        "\n",
        "        Args:\n",
        "            s (array) : 가중치-편향 연산된 가중합 a1\n",
        "            \n",
        "        Retruns:\n",
        "            1 / (1+np.exp(-s)) (array)\n",
        "  \"\"\"\n",
        "  return 1 / (1+np.exp(-s))"
      ],
      "metadata": {
        "id": "yrUtc-5uJDHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(y_pred, y_true):\n",
        "  \"\"\"\n",
        "    정확도 연산 기능 구현 함수\n",
        "\n",
        "        Args:\n",
        "            y_pred (list) : batch_size 별 순전파를 진행한 모델의 예측 값(1 또는 0)을 담은 sigmoid_output 배열\n",
        "            y_true (Series) : batch_size 별 실제 타겟 값\n",
        "\n",
        "        Retruns:\n",
        "            minibatch_accuracy (float) : batch_size 별 정확도 평균 값\n",
        "            \n",
        "        Note:\n",
        "            check_match : y_pred와 y_true의 일치 여부 확인 후 일치하는 수 만큼 cnt 증가\n",
        "  \"\"\"\n",
        "  cnt = 0\n",
        "  minibatch_accuracy = 0\n",
        "  check_match = np.equal(y_pred,y_true)\n",
        "\n",
        "  for correct in check_match:\n",
        "    if correct:\n",
        "      cnt+=1\n",
        "\n",
        "  minibatch_accuracy = cnt/len(y_pred)\n",
        "\n",
        "  return minibatch_accuracy"
      ],
      "metadata": {
        "id": "E2X8xzdivlPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_loss(y_pred, y_true):\n",
        "  \"\"\"\n",
        "    손실(교차 엔트로피)값 연산 기능 구현 함수\n",
        "    \n",
        "        Args:\n",
        "            y_pred (array) : batch_size 별 순전파를 진행한 모델의 확률 값을 담은 output 배열\n",
        "            y_true (Series) : batch_size 별 실제 타겟 값\n",
        "\n",
        "        Retruns:\n",
        "            second (float) : batch_size 별 loss 평균 값\n",
        "  \"\"\"\n",
        "  first = y_true * np.log(y_pred + 1e-7)\n",
        "  second = -np.sum(first)\n",
        "\n",
        "  return second"
      ],
      "metadata": {
        "id": "mRz63b7jvbQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  data = data_load('/content/binary_dataset.csv')\n",
        "  data = data_shuffle(data)\n",
        "  X_train, y_train = train_data_split(data)\n",
        "  X_test, y_test = test_data_split(data)\n",
        "  w1, b1 = initialization_parameter(X_train.shape[1])\n",
        "  accuracy, loss = model_train(X_train, y_train, w1, b1, 4)\n",
        "  print(f\"[Epoch 1] TrainData - Loss = {loss}, Accuracy = {accuracy}\")"
      ],
      "metadata": {
        "id": "19HKLGrrpDVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "id": "icotKf48TF3q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
